{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Demonstration of DCBC evaluation using GPU acceleration\n",
    "This notebook shows an quick example of a Distance controlled boundary coefficient (DCBC) evaluation between numpy cpu vs. pytorch gpu version.\n",
    "\n",
    "## Installation and Dependencies\n",
    "Ensure Python version >= 3.6 and pip installable on your system.\n",
    "\n",
    "`pip install nibabel scipy numpy sklearn matplotlib torch`\n",
    "\n",
    "To use PyTorch GPU acceleration, please install the correct PyTorch and CUDA version. Detailed torch+cuda installation can be found in PyTorch official webpage at https://pytorch.org/\n",
    "\n",
    "Below is a quick example of DCBC evaluation using CPU and GPU, and the speed comparison when evaluating `Choi 2012` 7 parcellation of striatum. In this example, we only focus on speed comparison between CPU and GPU version, the detailed step-by-step volumetric parcellation evaluation can be found elsewhere in notebook `example_volume.ipynb`.\n",
    "\n",
    "## 1. Numpy CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nibabel as nb\n",
    "from utilities import compute_dist, plot_single\n",
    "from dcbc import compute_DCBC\n",
    "\n",
    "# Load mask voxel index\n",
    "vol_ind = mat73.loadmat('../data/striatum_avrgDataStruct.mat')['volIndx']\n",
    "vol_ind = vol_ind.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parcellation given the mask file or voxel indices\n",
    "parcel_mni = nb.load('../parcellations/volume_striatum/masked_par_choi_7.nii.gz').get_fdata()\n",
    "coord = np.unravel_index(vol_ind - 1, parcel_mni.shape, 'F')  # Note: the linear indexing in numpy is column-order\n",
    "parcels = np.rint(parcel_mni[coord[0], coord[1], coord[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4135, 4135)\n"
     ]
    }
   ],
   "source": [
    "# Compute the distance matrix between voxel pairs using the mask file, numpy default C-order\n",
    "coord = np.asarray(coord).transpose()\n",
    "dist = compute_dist(coord, 2, backend='numpy')\n",
    "print(dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functional profile (betas) and several parameters for evaluation settings\n",
    "T = mat73.loadmat('../data/striatum_avrgDataStruct.mat')['T']\n",
    "returnsubj = [2,3,4,6,8,9,10,12,14,15,17,18,19,20,21,22,24,25,26,27,28,29,30,31]\n",
    "session, maxDist, binWidth = 1, 90, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start the real DCBC evaluation on the given parcellation using selected subjects and given experiment settings. So here we set the bin width = 5 mm, the maximum distance between any pair of voxels is 90 mm. We only use subjects session 1 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy CPU version DCBC calculation used 90.6093s\n"
     ]
    }
   ],
   "source": [
    "wcorr_array, bcorr_array, dcbc_array = np.array([]), np.array([]), np.array([])\n",
    "\n",
    "tic = time.perf_counter()\n",
    "for sub in returnsubj:\n",
    "    data = T['data'][(T['SN'] == sub) & (T['sess'] == session)].T\n",
    "    R = compute_DCBC(maxDist=maxDist, func=data, dist=dist, binWidth=binWidth, parcellation=parcels, backend='numpy')\n",
    "    wcorr_array = np.append(wcorr_array, R['corr_within'])\n",
    "    bcorr_array = np.append(bcorr_array, R['corr_between'])\n",
    "    dcbc_array = np.append(dcbc_array, R['DCBC'])\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Numpy CPU version DCBC calculation used {toc - tic:0.4f}s\")\n",
    "# print(wcorr_array, bcorr_array, dcbc_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Torch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from utilities import convert_numpy_to_torch_sparse\n",
    "\n",
    "DEVICE = 'cuda' if pt.cuda.is_available() else 'cpu'\n",
    "pt.set_default_tensor_type(pt.cuda.FloatTensor\n",
    "                           if pt.cuda.is_available() else\n",
    "                           pt.FloatTensor)\n",
    "\n",
    "# Covert input parcellation and distance from numpy to torch tensor first\n",
    "parcels = pt.tensor(parcels, dtype=pt.get_default_dtype())\n",
    "dist = compute_dist(coord, 2, backend='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch GPU version DCBC calculation used 1.1822s\n"
     ]
    }
   ],
   "source": [
    "wcorr_array, bcorr_array, dcbc_array = [],[],[]\n",
    "\n",
    "tic = time.perf_counter()\n",
    "for sub in returnsubj:\n",
    "    data = T['data'][(T['SN'] == sub) & (T['sess'] == session)].T\n",
    "    data = pt.tensor(data, dtype=pt.get_default_dtype())\n",
    "    R = compute_DCBC(maxDist=maxDist, func=data, dist=dist, binWidth=binWidth, parcellation=parcels, backend='torch')\n",
    "    wcorr_array.append(R['corr_within'])\n",
    "    bcorr_array.append(R['corr_between'])\n",
    "    dcbc_array.append(R['DCBC'])\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"PyTorch GPU version DCBC calculation used {toc - tic:0.4f}s\")\n",
    "# print(wcorr_array, bcorr_array, dcbc_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the PyTorch GPU version only takes 1.2 second to evaluate the parcellation on all 24 subjects' data, comparing to the Numpy CPU version which takes 90 seconds. Therefore, we highly recommend to use our DCBC toolbox in GPU version, especially if you have large sample size.\n",
    "\n",
    "Note, the current DCBC GPU version requires the distance matrix / subject's functional data can be loaded into GPU as a whole piece. The data streamer is not available now. Therefore, it is likely you encounter a `CUDA out of memory` error for large tensor. If that happens, please use PyTorch CPU tensor computation by set the cuda global flag to Flase, as `pt.cuda.is_available = lambda : False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the Apple M1/M2 chip is supported in PyTorch version 2.0 and above. The MAC user who wanted to run DCBC on M1/M2 chip can replace the `set_default_tensor_type()` flag with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.set_default_device('mps')\n",
    "pt.set_default_dtype(pt.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
